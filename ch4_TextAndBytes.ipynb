{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 텍스트와 바이트\n",
    "파이썬 3부터는 인간이 사용하는 텍스트 문자열과 원시 바이트 시퀀스를 엄격히 구분하기 시작했다. 암묵적으로 바이트 시퀀스를 유니코드 텍스트로 변환하는 것은 과거의 일이다. 이 장에서는 유니코드 문자열, 이진 시퀀스, 그리고 이 둘 간의 변환에 사용되는 인코딩에 대해 설명한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 문자열\n",
    "유니코드 표준은 문자의 단위 원소와 특정 바이트 표현을 명확히 구분한다.\n",
    "<li>문자의 단위 원소(코드 포인트, code point)는 10진수 0에서 1,114,111까지의 숫자이며, 유니코드 표준에서는 'U+' 접두사를 붙여 4자리에서 6자리 사이의 16진수로 표현한다. 예를 들어 A라는 문자는 코드 포인트 U+0041에, 유로화 기호는 U+20AC에 음악에서 사용하는 높은음 자리표는 U+1DD11E에 할당되어 있다.</li>\n",
    "<li>문자를 표현하는 실제 바이트는 사용하는 인코딩에 따라 달라진다. 인코딩은 코드 포인트를 바이트 시퀀스로 변환하는 알고리즘이다. 문자 A(U+0041)에 대한 코드 포인트는 UTF-8 인코딩에서는 1바이트\\x41, UTF-16LE 인코딩에서는 2바이트 \\x41\\x00으로 인코딩된다. 그리고 유로화 기호(U+20AC)는 UTF-8에서는 3바이트 \\xe2\\x82\\xac로 UTF-16LE에서는 2바이트 \\xac\\x20으로 인코딩된다.</li>\n",
    "\n",
    "코드 포인트를 바이트로 변환하는 것을 인코딩, 바이트를 코드 포인트로 변환하는 것을 디코딩이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b'caf\\xc3\\xa9'\n",
      "5\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-1 인코딩과 디코딩\n",
    "s = 'café'\n",
    "print(len(s))\n",
    "b = s.encode('utf8') # 바이트로 암호화\n",
    "print(b)             # byte 문자는 접두사 b로 시작한다.\n",
    "print(len(b))        # byte형인 b는 다시 바이트로 구성된다. e가 UTF-8에서 두 바이트로 인코딩되기 때문이다.\n",
    "print(b.decode('utf8')) # 다시 str로 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 바이트에 대한 기본 지식\n",
    "이진 시퀀스를 위해 사용되는 내장 자료형은 byte와 bytearray이다. 각 항목은 0에서 255사이의 정수로 구성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "99\n",
      "b'c'\n",
      "bytearray(b'caf\\xc3\\xa9')\n",
      "bytearray(b'\\xa9')\n"
     ]
    }
   ],
   "source": [
    "cafe = bytes('café', encoding = 'utf_8') # str에 인코딩을 지정해서 바이트를 생성\n",
    "print(cafe)\n",
    "print(cafe[0]) # 각 바이트는 0~255 수로 구성되어 있다.\n",
    "print(cafe[:1]) # 바이트를 슬라이싱하면 길이가 1이더라도 바이트가 반환된다.\n",
    "cafe_arr = bytearray(cafe)\n",
    "print(cafe_arr)\n",
    "print(cafe_arr[-1:]) # 바이트 배열 슬라이스도 바이트 배열이 반환된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bytes와 bytearray는 str의 format()과 format_map()를 제외하고 모든 메서드를 지원하며, casefold(), isdecimal(), isidentifier(), isnumeric(), isprintable(), encode() 등 유니코드 데이터에 관련된 메서드를 추가로 지원한다. bytes나 bytearray 객체를 생성하는 방법은 다음과 같다.\n",
    "<p><li>str과 encoding 키워드 인수</li>\n",
    "<li>0에서 255사이의 값을 제공하는 반복 가능형</li>\n",
    "<li>bytes, bytearray, memoryview, array.array 등 버퍼 프로토콜을 구현하는 객체, 이 메서드를 사용하면 원본 객체의 바이트를 복사해서 바이트 시퀀스를 새로 생성한다.</li></p>\n",
    "<p>버퍼 등의 객체로부터 이진 시퀀스를 생성하는 방법은 저수준 연산으로, 형변환이 필요할 수 있다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('h', [-2, -1, 0, 1, 2])\n",
      "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-3 배열의 원시 데이터에서 bytes 초기화하기\n",
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "print(numbers)\n",
    "octets = bytes(numbers)\n",
    "print(octets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 구조체와 메모리 뷰\n",
    "struct 모듈은 패킹된 바이트를 다양한 형의 필드로 구성된 튜플로 분석하고, 이와 반대로 튜플을 패킹된 바이트로 변환하는 함수를 제공한다. struct는 bytes, bytearray, memoryview 객체와 함께 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'GIF89a\\xd5\\x02\\xe9\\x01'\n",
      "(b'GIF', b'89a', 725, 489)\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-4] memoryview와 struct를 사용해서 GIF 이미지 헤더 조사하기\n",
    "import struct\n",
    "fmt = '<3s3sHH' # <는 리틀엔디언, 3s3s는 3바이트 시퀀스 두 개, HH는 16비트 정수 두 개를 나타낸다.\n",
    "with open('wave.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read()) # 메모리에 로딩된 파일 내용으로부터 memoryview를 생성한다.\n",
    "    \n",
    "header = img[:10] #\n",
    "print(bytes(header))\n",
    "print(struct.unpack(fmt, header))\n",
    "del header\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 기본 인코더/디코더\n",
    "텍스트를 바이트로 혹은 바이트를 텍스트로 변환하기 위해 파이썬 배포본에는 100여 개의 코덱이 포함되어 있다. 코덱은 open(), str.encode(), bytes.decode() 등의 함수를 호출할 때 encoding 인수에 전달해서 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1/tb'EL nino'\n",
      "utf_8/tb'EL nino'\n",
      "utf_16/tb'\\xff\\xfeE\\x00L\\x00 \\x00n\\x00i\\x00n\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-5] 전혀 다른 바이트 시퀀스를 만드는 세 개의 코덱으로 인코딩한 문자열\n",
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, 'EL nino'.encode(codec), sep='/t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 인코딩/디코딩 문제\n",
    "유니코드 에러가 발생할 때는 먼저 예외의 정확한 유형을 알아내야 한다. 문제를 해결하려면 먼저 인코딩 에러가 UnicodeEncodeErr인지 혹은 UnicodeDecodeErr인지 SyntaxError 등 다른 에러인지 구체적인 유형을 알아내야 한다. \n",
    "#### 4.4.1 UnicodeEncodeErr\n",
    "대부분 UTF가 아닌 코덱은 유니코드 문자가 대상 인코딩에 모두 정의되어 있지 않기 때문에 errors 인수에 별도의 처리기를 지정하지 않는 한 UnicodeEncodeErr를 발생시킬 여지가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0fdacefe200f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf_8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf_16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cp437'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 인코딩 시 ã에 매칭되는 byte가 정의되어 있지 않은 코덱을 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\shyeo\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\encodings\\cp437.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, errors)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "city = 'São Paulo'\n",
    "city.encode('utf_8')\n",
    "city.encode('utf_16')\n",
    "city.encode('cp437') # 인코딩 시 ã에 매칭되는 byte가 정의되어 있지 않은 코덱을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'So Paulo'\n",
      "b'S?o Paulo'\n",
      "b'S&#227;o Paulo'\n"
     ]
    }
   ],
   "source": [
    "print(city.encode('cp437', errors='ignore'))  # 에러 부분을 건너뜀 (일반적으로 좋지 않음)\n",
    "print(city.encode('cp437', errors='replace')) # 인코딩 할 수 없는 문자를 ?표시로 치환\n",
    "print(city.encode('cp437', errors='xmlcharrefreplace')) # 인코딩 할 수 없는 문자를 XML 개체로 치환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 UnicodeDecodeErr\n",
    "모든 바이트가 아스키 문자가 될 수 없으며, 모든 바이트 시퀀스가 UTF-8 이나 UTF-16 문자가 되는 것은 아니므로 이 때 UnicodeDecodeError가 발생한다. 그렇지만 'cp1252', 'iso8859_1', 'koi8_r' 등 많은 레거시 8비트 코덱은 무작위 비트 배열에 대해서도 에러를 발생시키지 않고 잘못된 바이트 스트림으로 디코딩 할 수 있어 주의가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "Montrιal\n",
      "MontrИal\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e90095dbd4da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iso8859_7'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'koi8_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf_8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "octets = b'Montr\\xe9al'\n",
    "print(octets.decode('cp1252'))\n",
    "print(octets.decode('iso8859_7'))\n",
    "print(octets.decode('koi8_r'))\n",
    "print(octets.decode('utf_8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montr�al\n"
     ]
    }
   ],
   "source": [
    "print(octets.decode('utf_8', errors='replace')) # �는 알 수 없는 문자를 표현하기 위해 사용하는 공식 유니코드 치환 문자이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 잘못된 코덱으로 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError\n",
    "파이선 3부터는 UTF-8을 소스 코드의 기본 인코딩 방식으로 사용한다. 따라서 인코딩 선언없이 비 UTF-8로 인코딩된 py모듈을 로딩하면 에러가 발생한다. 다만 파일 제일 처음에 코덱을 명시하여 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá Mundo\n"
     ]
    }
   ],
   "source": [
    "# coding: cp1252\n",
    "\n",
    "print('Olá Mundo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4 바이트 시퀀스의 인코딩 방식을 알아내는 방법\n",
    "Chardet는 규칙과 제한을 고려하여 30가지 인코딩 방식을 추정한다. chardetect라는 명령행 유틸리티도 포함하고 있다.\n",
    "<p><b>$ chardetect 04-text-bypte.asciidoc</b></p>\n",
    "<p>04-text-bypte.asciidoc: utf-8 with confidence 0.99</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.5 BOM : Byte Order Mark\n",
    "<a href=\"https://ko.wikipedia.org/wiki/%EC%97%94%EB%94%94%EC%96%B8\">엔디언(Endianness)</a>은 컴퓨터의 메모리와 같은 1차원의 공간에 여러 개의 연속된 대상을 배열하는 방법을 뜻하며, 바이트를 배열하는 방법을 특히 바이트 순서(Byte order)라 한다. 엔디언은 보통 큰 단위가 앞에 나오는 빅 엔디언(Big-endian)과 작은 단위가 앞에 나오는 리틀 엔디언(Little-endian)으로 나눌 수 있으며, 두 경우에 속하지 않거나 둘을 모두 지원하는 것을 미들 엔디언(Middle-endian)이라 부르기도 한다. 엔디언은 한 바이트 이상을 워드로 사용하는 UTF-16, UTF-32에서만 영향을 준다. UTF-8은 엔디언 특성과 상관없이 동일한 바이트 시퀀스를 생성하므로 BOM이 필요없으나 윈도우 APP 중에서는 BOM(b'\\xef\\xbb\\xbf')을 붙이는 경우가 있으므로 참고해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfeE\\x00L\\x00 \\x00n\\x00i\\x00n\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "u16 = 'EL nino'.encode('utf_16')\n",
    "print(u16) # b'\\xff\\xfe' 는 바이트 순서 표시(BOM)로 리틀 엔디언(little endian)을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 254, 69, 0, 76, 0, 32, 0, 110, 0, 105, 0, 110, 0, 111, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(u16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "255, 254는 리틀엔디언을 의미하는 b'\\xff\\xfe' 이며, 69, 0은 첫 문자 'E'를 의미한다. 빅엔디언이라면 0, 69 순으로 반대로 표현된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E\\x00L\\x00 \\x00n\\x00i\\x00n\\x00o\\x00'\n",
      "b'\\x00E\\x00L\\x00 \\x00n\\x00i\\x00n\\x00o'\n"
     ]
    }
   ],
   "source": [
    "u16 = 'EL nino'.encode('utf_16le') # BOM을 붙이지 않음\n",
    "print(u16) \n",
    "u16 = 'EL nino'.encode('utf_16be') # BOM을 붙이지 않음\n",
    "print(u16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 텍스트 파일 다루기\n",
    "유니코드 샌드위치란 파일을 일기 위해 여는 등 입력할 때 가능하면 빨리 bytes를 str로 변환해야 하며, 가능한 늦게 str을 bytes로 인코딩한다. 또한 여러 상황의 컴퓨터에서 실행을 감안하여 인코딩 기본값에 의존하지말고 endoding 인수를 명시적으로 지정하는 것이 좋다. ![alt text](unicodesandwich.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caf챔'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [예제 4-9] cp1252를 기본으로 사용하는 윈도우에서는 잘못된 인코딩을 한다.\n",
    "open('cafe.txt', 'w', encoding = 'utf_8').write('cafè') # utf_8로 기록\n",
    "open('cafe.txt').read() # 윈도우에서는 open('cafe.txt', 'r', encoding = 'cp1252').read()로 동작함(기본값 cp1252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>\n",
      "4\n",
      "os.stat_result(st_mode=33206, st_ino=2814749767210380, st_dev=209934011, st_nlink=1, st_uid=0, st_gid=0, st_size=5, st_atime=1540457103, st_mtime=1540626351, st_ctime=1540457103)\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-10], 예제 4-9의 확장\n",
    "fp = open('cafe.txt', 'w', encoding = 'utf_8')\n",
    "print(fp)\n",
    "print(fp.write('cafè')) # 4자를 입력\n",
    "fp.close()\n",
    "\n",
    "import os\n",
    "print(os.stat('cafe.txt')) # è가 2바이트로 변환되기 때문에 st_size가 5bytes로 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>\n",
      "cp1252\n",
      "cafÃ¨\n"
     ]
    }
   ],
   "source": [
    "fp2 = open('cafe.txt', 'r', encoding = 'cp1252')\n",
    "print(fp2)\n",
    "print(fp2.encoding)\n",
    "print(fp2.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'>\n",
      "UTF-8\n",
      "cafè\n"
     ]
    }
   ],
   "source": [
    "fp3 = open('cafe.txt', 'r', encoding = 'UTF-8')\n",
    "print(fp3)\n",
    "print(fp3.encoding)\n",
    "print(fp3.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='cafe.txt'>\n",
      "b'caf\\xc3\\xa8'\n"
     ]
    }
   ],
   "source": [
    "fp3 = open('cafe.txt', 'rb')\n",
    "print(fp3)\n",
    "print(fp3.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코딩 방식을 알아내기 위해 파일 내용을 분석하는 경우가 아니라면 텍스트 파일을 이진 모드로 열지 않는 것이 좋으며, 인코딩 방식을 확인할 때도 Chardet 모듈을 사용하는 것이 좋다. 일반적으로 래스터 이미지 등 이진 파일을 열 때만 이진 모드를 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 기본 인코딩 설정\n",
    "가장 중요한 인코딩 설정은 locale.getpreferredenciding() 함수가 반환하는 설정이다. 리눅스/GNU/OS X는 수년간 기본적으로 모든 인코딩이 UTF-8로 설정되었지만, 윈도우에서는 동일한 시스템 안에 여러 인코딩이 사용되므로 기본 인코딩에 의존하지 않는 것이 가장 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'cp949'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'cp949'\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "            sys.stdin.encoding -> '949'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-11] 인코딩 기본값 확인\n",
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "locale.getpreferredencoding()\n",
    "type(my_file)\n",
    "my_file.encoding\n",
    "sys.stdout.encoding\n",
    "sys.stdout.isatty()\n",
    "sys.stdin.encoding\n",
    "sys.stderr.isatty()\n",
    "sys.stderr.encoding\n",
    "sys.getdefaultencoding()\n",
    "sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'cp949'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'cp949'\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "            sys.stdin.encoding -> '949'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'mbcs'\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-11] window 인코딩 기본값 확인\n",
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "locale.getpreferredencoding()\n",
    "type(my_file)\n",
    "my_file.encoding\n",
    "sys.stdout.encoding\n",
    "sys.stdout.isatty()\n",
    "sys.stdin.encoding\n",
    "sys.stderr.isatty()\n",
    "sys.stderr.encoding\n",
    "sys.getdefaultencoding()\n",
    "sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 제대로 비교하기 위해 유니코드 정규화하기\n",
    "유니코드에는 결합 문자가 있기 때문에 문자열 비교가 간단하지 않다. 앞 문자에 연결되는 발음구별 기회(diacritical mark)는 인쇄할 때 앞 문자와 하나로 결합되어 출력된다. 예를 들어 'cafè'는 네 개나 다섯 개의 코드 포인트를 이용해서 두 가지 방식으로 표현할 수 있지으며 결과는 동일하지만 서로 동일하지 않다고 판단하는 문제가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafè café\n",
      "4 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'cafè'\n",
    "s2 = 'cafe\\u0301' # \\u0301는 앞문자와 결합하는 combining acute accent\n",
    "print(s1, s2)\n",
    "print(len(s1), len(s2))\n",
    "s1 == s2 # 결과는 같으나 동일하지 않다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제를 해결하려면 unicodedata.normalize() 함수가 제공하는 유니코드 정규화를 이용해야 한다. 이 함수의 첫 인수는 정규화 방식인 NFC, NFD, NFKC, NFKD 중 하나여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "4 4\n",
      "5 5\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'cafè'\n",
    "s2 = 'cafe\\u0301'\n",
    "print(len(s1), len(s2))\n",
    "print(len(normalize('NFC', s1)), len(normalize('NFC', s2))) # W3C가 추천하는 정규화 형식이기도 하다\n",
    "print(len(normalize('NFD', s1)), len(normalize('NFD', s2)))\n",
    "\n",
    "print(len(normalize('NFC', s1)) == len(normalize('NFC', s2)))\n",
    "print(len(normalize('NFD', s1)) == len(normalize('NFD', s2)))\n",
    "\n",
    "# NFKC, NFKD는 정보를 왜곡할 수 있지만 검색 및 색인 생성을 위한 편리한 중간 형태를 생성할 수 있다. 다만 영구 저장할 때는 데이터가 손실될 수 있기 때문에 사용을 삼가해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 케이스 폴딩\n",
    "본질적으로 케이스 폴딩은 모든 텍스트를 소문자로 변환하는 연산이며 유니코드인 경우 약간의 변환을 동반한다. str.casfold() 메서드를 이용한다. 파이선 3.4에는 str.casefold()와 str.lower()가 서로 다른 분자를 반환하는 코드 포인트가 116개 있다. 이 수치는 유니코드 6.3에서 명명된 110,122개 문자의 0.11%에 해당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEK SMALL LETTER MU\n",
      "μ\n",
      "LATIN SMALL LETTER SHARP S\n",
      "ss\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "micro = 'μ'\n",
    "print(name(micro))\n",
    "micro_cf = micro.casefold()\n",
    "print(micro_cf)\n",
    "\n",
    "eszett = 'ß'\n",
    "print(name(eszett))\n",
    "eszett_cf = eszett.casefold()\n",
    "print(eszett_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 정규화된 텍스트 매칭을 위한 유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==\n",
    "            normalize('NFC', str1).casefold())\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "\n",
    "print(nfc_equal(s1, s2))\n",
    "print(nfc_equal('A', 'a'))\n",
    "\n",
    "print(nfc_equal(s3, s4))\n",
    "print(fold_equal(s3, s4))\n",
    "print(fold_equal(s1, s2))\n",
    "print(fold_equal('A', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 극단적인 '정규화' : 발음 구별 기호 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "Ζέφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-16] 라틴 문자에서 결합표시 기호를 제거하는 함수\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\" 라틴식 문자에서 발음 구별 기회를 모두 제거 \"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt) # 모든 문자를 기본 문자와 결합표시로 분해\n",
    "    \n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base: # 앞 문자가 라틴 문자이며 현재 문자가 결합문자인 경우 건너뜀(제거)\n",
    "            continue\n",
    "        keepers.append(c)\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters # 라틴 문자인지 확인\n",
    "\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(shave_marks(order))\n",
    "\n",
    "Greek = 'Ζέφυρος, Zéfiro' # 라틴 알파벳인 경우만 발음기호를 제거\n",
    "print(shave_marks(Greek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [예제 4-17] 서양 활자(타이포그래픽) 기회를 아스키로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\", # 문자대 문자 치환을 위한 매핑 테이블\n",
    " \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({ # 문자대 문자열 치환을 위한 매핑 테이블\n",
    " '€': '<euro>',\n",
    " '…': '...',\n",
    " 'Œ': 'OE',\n",
    " '™': '(TM)',\n",
    " 'œ': 'oe',\n",
    " '‰': '<per mille>',\n",
    " '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map) # 매핑 테이블을 병합\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Win1252 기호를 아스키 문자나 시퀀스로 치환한다.\"\"\"\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks(dewinize(txt)) # 발음 기호를 제거\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks) # 호환성 코드 보인트로 대체된 문자열을 만든다.\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(dewinize(order))\n",
    "print(asciize(order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 유니코드 텍스트 정렬하기\n",
    "문자열의 경우 각 단어의 코드 포인트를 비교하지만 아스키 문자가 아닌경우 부적절한 결과가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'atemoia', 'açaí', 'caju', 'cajá']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits) # cajá의 순서가 올바르지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서는 이러한 경우 locale.strfrm() 함수를 이용해서 변환하는 것이 표준이다. 다만 먼저 애플리케이션에 대해 적절히 현지어를 설정하고 OS가 이 설정을 지원해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'atemoia', 'açaí', 'caju', 'cajá']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "#locale.setlocale(locale.LC_COLLATE, 'fr_FR.UTF-8') # 내 경우에는 지원하지 않아 주석 처리함\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "sorted_fruits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7.1 유니코드 대조 알고리즘을 이용한 정렬\n",
    "PyUCA( https://pypi.python.org/pypi/pyuca/ )는 순수 파이썬으로 구현한 유니코드 대조 알고리즘(Unicode Collation Algorithm, UCA)이다. [예제 4-20]에서 보는 것처럼 PyUCA를 사용하는 방법은 아주 간단하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [예제 4-20] pyuca.Collator.sort_Key() 메서드 사용하기\n",
    "import pyuca\n",
    "coll = pyuca.Collator() # 지역 정보를 고려하지 않는다.\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "sorted_fruits \n",
    "# 정렬 방식을 커스터마이즈하려면 Collator() 생성자에 직접 만든 대조 테이블에 대한 경로를 제공한다. 이 테이블은 유니코드 데이터베이스를 구성하는 여러 테이블 중 하나이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 유니코드 데이터베이스\n",
    "유니코드 표준은 수많은 구조화된 텍스트 파일의 형태로 하나의 완전한 데이터베이스를 제공한다. 때문에 문자인지, 십진수인자, 다른 수치형 기호인지를 기록한다. str의 isidentifier(), isprintable(), isdecimal(), isnumeric(), casefold() 메서드는 이 데이터베이스를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-21] 유니코드 데이터베이스 수치형 문자 메타데이터 사용 예\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample:\n",
    "    print ('U+%04x' % ord(char),\n",
    "           char.center(6), # 문자를 6자리 중 중앙으로 배치\n",
    "           're_dig' if re_digit.match(char) else '-', # re 모듈은 유니코드를 잘 인식하지 못한다. PyPI를 통해 새로 제공되는 regex 모듈은 re 모듈을 대체하기 위해 만들어졌으며 유니코드를 더욱 잘 지원한다.\n",
    "           'isdig' if char.isdigit() else '-', \n",
    "           'isnum' if char.isnumeric() else '-',\n",
    "           format(unicodedata.numeric(char), '5.2f'),\n",
    "           unicodedata.name(char),\n",
    "           sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 이중 모드 str 및 bytes API\n",
    "표준 라이브러리에는 str이나 bytes 인수를 모두 받으며, 인수의 자료형에 따라 다르게 작동하는 함수들이 있다. re와 os모듈이 대표적인 예다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9.1 정규 표현식에서의 str과 bytes\n",
    "bytes로 정규 표현식을 만들면 \\d와 \\w같은 패턴은 아스키 문자만 매치되지만, str로 이 패턴을 만들면 아스키 문자 이외에 유니코드 숫자나 문자도 매칭된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729 = 13 + 123 = 93 + 103 '\n",
      "Numbers\n",
      " str: ['௧௭௨௯', '1729', '13', '123', '93', '103']\n",
      " bytes [b'1729', b'13', b'123', b'93', b'103']\n",
      "Words\n",
      " str: ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '13', '123', '93', '103']\n",
      " bytes [b'Ramanujan', b'saw', b'as', b'1729', b'13', b'123', b'93', b'103']\n"
     ]
    }
   ],
   "source": [
    "# [예제 4-22] ramanujan.py: 간단한 str과 bytes 정규 표현식의 동작 비교\n",
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r'\\d+') # str 형\n",
    "re_words_str = re.compile(r'\\w+')   # str 형\n",
    "re_numbers_bytes = re.compile(b'\\d+') # bytes 형\n",
    "re_words_bytes = re.compile(b'\\w+')   # bytes 형\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"\n",
    "           \" as 1729 = 13 + 123 = 93 + 103 \")\n",
    "\n",
    "text_bytes = text_str.encode('utf_8')\n",
    "\n",
    "\"\"\" 정규 표현식을 str과 bytes에 사용할 수 있지만 바이트에 정규식을 사용하면 아스키 범위를 벗어나는 문자들은 숫자나 단어로 처리하지 않는다. \"\"\"\n",
    "print('Text', repr(text_str), sep='\\n ')\n",
    "print('Numbers')\n",
    "print(' str:', re_numbers_str.findall(text_str))\n",
    "print(' bytes', re_numbers_bytes.findall(text_bytes))\n",
    "print('Words')\n",
    "print(' str:', re_words_str.findall(text_str))\n",
    "print(' bytes', re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".git\n",
      "b'.git'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pi_name_bytes = os.listdir(b'.')[0]\n",
    "#pi_name_bytes = b'digits-of-\\xcf\\x80.txt'\n",
    "pi_name_str = pi_name_bytes.decode(encoding='ascii', errors='surrogateescape') # ascii로 디코딩 할 수 없는 바이트 유니코드 표준에서 '하위 써로케이트 영역'이라고 하는 U+DC00 ~ U+DCFF까지의 코드 포인트로 치환한다.\n",
    "print(pi_name_str)\n",
    "print(pi_name_str.encode(encoding='ascii', errors='surrogateescape'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
